{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "from matplotlib.figure import Figure\n",
    "from PIL import Image\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoProcessor:\n",
    "    def __init__(self, \n",
    "                 modelFile=\"../models/res10_300x300_ssd_iter_140000.caffemodel\",\n",
    "                 configFile = \"../models/deploy.prototxt\",\n",
    "                 landmarkFile = \"../models/shape_predictor_68_face_landmarks.dat\",\n",
    "                 right_eye_file ='../models/haarcascade_righteye_2splits.xml',\n",
    "                 left_eye_file ='../models/haarcascade_lefteye_2splits.xml',\n",
    "                 mouth_file ='../models/haarcascade_smile.xml',\n",
    "                 max_interations = 10,\n",
    "                 conf_threshold = 0.60,\n",
    "                 nframesdiff = 2,\n",
    "                 normalized_dim = 500):\n",
    "        self.modelFile = modelFile\n",
    "        self.configFile = configFile\n",
    "        self.max_interations = max_interations\n",
    "        self.conf_threshold = conf_threshold\n",
    "        self.nframesdiff = nframesdiff\n",
    "        self.normalized_dim = normalized_dim\n",
    "        self.net = cv2.dnn.readNetFromCaffe(self.configFile, self.modelFile)\n",
    "        self.shape_predictor = dlib.shape_predictor(landmarkFile)\n",
    "        self.right_eye_casc = cv2.CascadeClassifier(right_eye_file)\n",
    "        self.left_eye_casc = cv2.CascadeClassifier(left_eye_file)\n",
    "        self.mouth_casc = cv2.CascadeClassifier(mouth_file)\n",
    "        self.mean = 128\n",
    "        self.min_YCrCb = np.array([0,133,77],np.uint8)\n",
    "        self.max_YCrCb = np.array([235,173,127],np.uint8)\n",
    "        self.h = 260\n",
    "        self.w = 208\n",
    "        \n",
    "        #self.min_HSV = np.array([0, 48, 80], dtype = \"uint8\")\n",
    "        #self.max_HSV = np.array([20, 255, 255], dtype = \"uint8\")\n",
    "        self.min_HSV = np.array([0, 58, 30], dtype = \"uint8\")\n",
    "        self.max_HSV = np.array([33, 255, 255], dtype = \"uint8\")\n",
    "\n",
    "\n",
    "    def extract_face_box(self, img):\n",
    "        (h, w) = img.shape[:2]\n",
    "        face_box = None\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (103.93, 116.77, 123.68))\n",
    "        self.net.setInput(blob)\n",
    "        detections = self.net.forward()\n",
    "        for i in range(detections.shape[2]):\n",
    "            if detections[0, 0, i, 2] > self.conf_threshold:\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                face_box = box.astype(\"int\")\n",
    "                break\n",
    "                    \n",
    "        return face_box\n",
    "\n",
    "    def extract_random_faces(self, filename, nframe=100, num_faces=1):\n",
    "        captured_faces = []\n",
    "        iterations = 0\n",
    "        v_cap = cv2.VideoCapture(filename)\n",
    "        v_length = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        while len(captured_faces) < num_faces and iterations < self.max_interations:\n",
    "            iterations += 1\n",
    "            # v_cap.set(1, np.random.randint(v_length)-1)\n",
    "            v_cap.set(1, nframe)\n",
    "            \n",
    "            ret, img = v_cap.read()\n",
    "        \n",
    "            if ret == True:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                (h, w) = img.shape[:2]\n",
    "                blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (103.93, 116.77, 123.68))\n",
    "                self.net.setInput(blob)\n",
    "                detections = self.net.forward()\n",
    "                for i in range(detections.shape[2]):\n",
    "                    confidence = detections[0, 0, i, 2]            \n",
    "                    if confidence > self.conf_threshold:\n",
    "                        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                        (x1, y1, x2, y2) = box.astype(\"int\")\n",
    "                        face = img[y1:y2, x1:x2]\n",
    "                        \n",
    "                        # normlize\n",
    "                        # face = cv2.resize(face, self.normalized_dim)\n",
    "                        captured_faces.append(face)\n",
    "        \n",
    "        # When everything done, release the video capture and video write objects\n",
    "        v_cap.release()\n",
    "    \n",
    "        return captured_faces\n",
    "\n",
    "    def landmark(self, face):\n",
    "        gray = cv2.cvtColor(face, cv2.COLOR_RGB2GRAY)\n",
    "        shape = self.shape_predictor(face,dlib.rectangle(0,0,face.shape[1],face.shape[0]))\n",
    "        coords = np.zeros((shape.num_parts, 2), dtype=\"int\")\n",
    "        for i in range(0, shape.num_parts):\n",
    "            coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "\n",
    "        return coords\n",
    "\n",
    "    def right_eye(self, face):\n",
    "        right_eye = self.right_eye_casc.detectMultiScale(\n",
    "            face,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=4,\n",
    "            flags=cv2.CASCADE_FIND_BIGGEST_OBJECT)\n",
    "        return right_eye[0]\n",
    "\n",
    "    def left_eye(self, face):\n",
    "        right_eye = self.left_eye_casc.detectMultiScale(\n",
    "            face,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=4,\n",
    "            flags=cv2.CASCADE_FIND_BIGGEST_OBJECT)\n",
    "        return right_eye[0]\n",
    "\n",
    "    def mouth(self, face):\n",
    "        right_eye = self.mouth_casc.detectMultiScale(\n",
    "            face,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=4,\n",
    "            flags=cv2.CASCADE_FIND_BIGGEST_OBJECT)\n",
    "        return right_eye[0]\n",
    "\n",
    "\n",
    "    def extract_diff(self, filename, nframe = 42, num_diff = 1):\n",
    "        captured_diff = np.empty(shape=(0,d,d,3), dtype=np.int8)\n",
    "        iterations = 0\n",
    "        v_cap = cv2.VideoCapture(filename)\n",
    "        v_length = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        while len(captured_diff) < num_diff and iterations < self.max_interations:\n",
    "            iterations += 1\n",
    "            v_cap.set(1, nframe)\n",
    "            ret, img_base = v_cap.read()\n",
    "            if ret == True:\n",
    "                v_cap.set(1, nframe + self.nframesdiff)\n",
    "                ret, img = v_cap.read()\n",
    "                \n",
    "            if ret == True:\n",
    "                img_base = cv2.cvtColor(img_base, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                face1 = cv2.resize(self.extract_face(img_base), (self.normalized_dim,self.normalized_dim))\n",
    "                face2 = cv2.resize(self.extract_face(img), (self.normalized_dim,self.normalized_dim))\n",
    "                if type(face1) == type(face2):\n",
    "                    face_diff = cv2.absdiff(face2,face1)\n",
    "                    # face_diff = cv2.absdiff(self.mean,face_diff)\n",
    "                    face_diff = cv2.normalize(face_diff,None,0,255,cv2.NORM_MINMAX)\n",
    "                    if face_diff is not None:\n",
    "                        captured_diff = np.append(captured_diff,[face_diff],axis=0)\n",
    "        \n",
    "        # When everything done, release the video capture and video write objects\n",
    "        v_cap.release()\n",
    "        \n",
    "        # Closes all the frames\n",
    "        cv2.destroyAllWindows() \n",
    "\n",
    "        return captured_diff\n",
    "\n",
    "    def extract_motion(self, filename, nframe = 42, num_motions = 1):\n",
    "        captured_motions = np.empty(shape=(0,d,d,3), dtype=np.int8)\n",
    "        hsv = np.empty(shape=(d,d,3), dtype=np.uint8)\n",
    "        iterations = 0\n",
    "        v_cap = cv2.VideoCapture(filename)\n",
    "        v_length = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        while len(captured_motions) < num_motions and iterations < self.max_interations:\n",
    "            iterations += 1\n",
    "            v_cap.set(1, nframe)\n",
    "            ret, img_base = v_cap.read()\n",
    "            if ret == True:\n",
    "                v_cap.set(1, nframe + self.nframesdiff)\n",
    "                ret, img = v_cap.read()\n",
    "                \n",
    "            if ret == True:\n",
    "                img_base = cv2.cvtColor(img_base, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                face1 = cv2.resize(self.extract_face(img_base), (self.normalized_dim,self.normalized_dim))\n",
    "                face2 = cv2.resize(self.extract_face(img), (self.normalized_dim,self.normalized_dim))\n",
    "                \n",
    "                if type(face1) == type(face2):\n",
    "                    face1 = cv2.cvtColor(face1, cv2.COLOR_RGB2GRAY)\n",
    "                    face2 = cv2.cvtColor(face2, cv2.COLOR_RGB2GRAY)\n",
    "                    hsv[...,1] = 255\n",
    "\n",
    "                    flow = cv2.calcOpticalFlowFarneback(face1, face2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "                    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "                    hsv[...,0] = ang*180/np.pi/2\n",
    "                    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "                    bgr = cv2.cvtColor(hsv,cv2.COLOR_HSV2RGB)\n",
    "                    if bgr is not None:\n",
    "                        captured_motions = np.append(captured_motions,[bgr],axis=0)\n",
    "        \n",
    "        # When everything done, release the video capture and video write objects\n",
    "        v_cap.release()\n",
    "        \n",
    "        # Closes all the frames\n",
    "        cv2.destroyAllWindows() \n",
    "\n",
    "        return captured_motions\n",
    "\n",
    "    def extract_skin(self, image):\n",
    "        imageYCrCb = cv2.cvtColor(image,cv2.COLOR_RGB2YCR_CB)\n",
    "        skinRegionYCrCb = cv2.inRange(imageYCrCb,self.min_YCrCb,self.max_YCrCb)\n",
    "        return (skinRegionYCrCb/255).sum(), cv2.bitwise_and(image, image, mask = skinRegionYCrCb)\n",
    "\n",
    "    def extract_skin_hue(self, image):\n",
    "        imagehsv = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "        skinRegionhsv = cv2.inRange(imagehsv,self.min_HSV,self.max_HSV)\n",
    "        return cv2.bitwise_and(image, image, mask = skinRegionhsv)\n",
    "\n",
    "    def extract(self, filename, output):\n",
    "        nfaces = 0\n",
    "        last_face_box = None\n",
    "        v_cap = cv2.VideoCapture(filename)\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "        v_out = cv2.VideoWriter(output,fourcc, 30, (2*self.normalized_dim,self.normalized_dim))\n",
    "\n",
    "        while True:\n",
    "            ret, img = v_cap.read()\n",
    "            if ret != True:\n",
    "                break\n",
    "            \n",
    "            # extract face\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            face_box = self.extract_face_box(img)\n",
    "\n",
    "            if face_box is None and last_face_box is not None:\n",
    "                face_box = last_face_box\n",
    "            \n",
    "            if face_box is not None:\n",
    "                z = np.zeros((self.normalized_dim,self.normalized_dim,3),dtype=\"uint8\")\n",
    "                (x1, y1, x2, y2) = face_box\n",
    "                (x1, y1, x2, y2) = ((x1+x2)//2-self.w//2, (y1+y2)//2-self.h//2,\n",
    "                                    (x1+x2)//2+self.w//2, (y1+y2)//2+self.h//2)\n",
    "                (npixels,face) = self.extract_skin(img[y1:y2, x1:x2])\n",
    "                # face = cv2.resize(face, (self.normalized_dim,self.normalized_dim))\n",
    "                (u1,u2,u3) = face.shape\n",
    "                z[0:u1,0:u2,0:u3] = face\n",
    "                frame = cv2.cvtColor(z, cv2.COLOR_RGB2BGR)\n",
    "                last_face_box = face_box\n",
    "                nfaces += 1\n",
    "            else:\n",
    "                frame = np.zeros((self.normalized_dim,self.normalized_dim,3),dtype=\"uint8\")\n",
    "\n",
    "            fig = Figure(figsize=(5, 5), dpi=100)\n",
    "            canvas = FigureCanvasAgg(fig)\n",
    "            ax = fig.add_subplot(111)\n",
    "\n",
    "            color = ('b','y','r')\n",
    "            face_hsv = cv2.cvtColor(face,cv2.COLOR_RGB2HSV)\n",
    "            for i,col in enumerate(color):\n",
    "                hist = cv2.calcHist([face_hsv],[i],None,[256],[0,256])/npixels\n",
    "                ax.plot(hist,color = col)\n",
    "                ax.set_ylim([.0, .3])\n",
    "\n",
    "            canvas.draw()\n",
    "            s, (width, height) = canvas.print_to_buffer()\n",
    "            im = Image.frombytes(\"RGBA\", (width, height), s)\n",
    "            fhist = cv2.cvtColor(np.array(im), cv2.COLOR_RGB2BGR)\n",
    "            v_out.write(np.hstack([frame,fhist]))\n",
    "                \n",
    "        v_out.release()\n",
    "        v_cap.release()\n",
    "        \n",
    "        # Closes all the frames\n",
    "        cv2.destroyAllWindows() \n",
    "        print(f'faces = {nfaces}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = VideoProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REAL 2/hszwwswewp.mp4\n",
    "# FAKE 2/szfiektjqw.mp4\n",
    "\n",
    "# REAL tejfudfgpq.mp4\n",
    "# FAKE imvbxbuhbp.mp4\n",
    "\n",
    "# REAL 48/cdpnnebwfa.mp4\n",
    "# FAKE 48/yyaicxrixg.mp4\n",
    "\n",
    "# REAL 20/ftxqeraryj.mp4\n",
    "# FAKE 20/kbjtcfcbys.mp4\n",
    "\n",
    "# REAL 14/urloiqxdwi.mp4\n",
    "# FAKE 14/ffztqatacr.mp4\n",
    "\n",
    "# REAL 20/stqcnfwzrv.mp4\n",
    "# FAKE 20/qelvshsgnv.mp4\n",
    "\n",
    "# REAL 2/oobeaklccb.mp4\n",
    "# FAKE 2/arcviozhqq.mp4\n",
    "\n",
    "# REAL 14/xdxfmvnghz.mp4 (side)\n",
    "# FAKE 14/xwymxohvup.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faces = 300\n"
     ]
    }
   ],
   "source": [
    "video_filename = '../videos/dfdc_train_part_14/xdxfmvnghz.mp4'\n",
    "output_filename = '../data/xdxfmvnghz_real.mp4'\n",
    "vp.extract(video_filename,output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faces = 300\n"
     ]
    }
   ],
   "source": [
    "video_filename = '../videos/dfdc_train_part_14/xwymxohvup.mp4'\n",
    "output_filename = '../data/xwymxohvup_fake.mp4'\n",
    "vp.extract(video_filename,output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
