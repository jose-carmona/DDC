{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from utils.ffmpeg_processor import ffmpegProcessor\n",
    "from utils.audio import melspectrogram, show_melspectrogram, save_melspectrogram\n",
    "from utils.encoder import FakeRealEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_p0 = [ 'dfdc_train_part_1',\n",
    "        'dfdc_train_part_2',\n",
    "        'dfdc_train_part_3',\n",
    "        'dfdc_train_part_4',\n",
    "        'dfdc_train_part_5',\n",
    "        'dfdc_train_part_6',\n",
    "        'dfdc_train_part_7',\n",
    "        'dfdc_train_part_8',\n",
    "        'dfdc_train_part_9' ]\n",
    "dir_p1 = [ 'dfdc_train_part_10',\n",
    "        'dfdc_train_part_11',\n",
    "        'dfdc_train_part_12',\n",
    "        'dfdc_train_part_13',\n",
    "        'dfdc_train_part_14',\n",
    "        'dfdc_train_part_15',\n",
    "        'dfdc_train_part_16',\n",
    "        'dfdc_train_part_17',\n",
    "        'dfdc_train_part_18',\n",
    "        'dfdc_train_part_19' ]\n",
    "dir_p2 = [ 'dfdc_train_part_20',\n",
    "        'dfdc_train_part_21',\n",
    "        'dfdc_train_part_22',\n",
    "        'dfdc_train_part_23',\n",
    "        'dfdc_train_part_24',\n",
    "        'dfdc_train_part_25',\n",
    "        'dfdc_train_part_26',\n",
    "        'dfdc_train_part_27',\n",
    "        'dfdc_train_part_28',\n",
    "        'dfdc_train_part_29' ]\n",
    "dir_p3 = [ 'dfdc_train_part_30',\n",
    "        'dfdc_train_part_31',\n",
    "        'dfdc_train_part_32',\n",
    "        'dfdc_train_part_33',\n",
    "        'dfdc_train_part_34',\n",
    "        'dfdc_train_part_35',\n",
    "        'dfdc_train_part_36',\n",
    "        'dfdc_train_part_37',\n",
    "        'dfdc_train_part_38',\n",
    "        'dfdc_train_part_39' ]\n",
    "dir_p4 = [ 'dfdc_train_part_40',\n",
    "        'dfdc_train_part_41',\n",
    "        'dfdc_train_part_42',\n",
    "        'dfdc_train_part_43',\n",
    "        'dfdc_train_part_44',\n",
    "        'dfdc_train_part_45',\n",
    "        'dfdc_train_part_46',\n",
    "        'dfdc_train_part_47',\n",
    "        'dfdc_train_part_48',\n",
    "        'dfdc_train_part_49' ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrk_dir = '../videos/'\n",
    "\n",
    "dirs = ['dfdc_train_part_49']\n",
    "\n",
    "vp = VideoProcessor()\n",
    "le = FakeRealEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrategia\n",
    "\n",
    "* Video a video\n",
    "* Extraemos caras de frames \n",
    "* Tenemos 300 frames\n",
    "* 3 frames: 1 frame cada 10 frames\n",
    "* 30 frames --> 10 muestras por video\n",
    "* ¿y si está en movimiento?\n",
    "* Nos quedamos con la capa H \n",
    "* comparamos con misma zona en video original\n",
    "* Si es diferente, guardamos la muestra fake y la misma muestra real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_real_audios(dir, metadata, ap, le, n_chunks, len_chunks, inc_chunk):\n",
    "    df = metadata.query('label == \"REAL\"')\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        ar = ap.extract_audio(f\"../videos/{dir}/{row.video}\")\n",
    "        ar = np.where((ar > -noise_level)&(ar < noise_level), 0, ar)\n",
    "        ar = np.resize(ar, (n_chunks,len_chunks))\n",
    "        for i in range(n_chunks):\n",
    "            save_melspectrogram(ar[i], \n",
    "                                f'REAL_{row.video}_{i}',\n",
    "                                le.to_categorical(['REAL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fake_audios(dir, metadata, ap, le, threshold, n_chunks, len_chunks, inc_chunk):\n",
    "    df = metadata.query('label == \"FAKE\"')\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        af = ap.extract_audio(f\"../videos/{dir}/{row.video}\")\n",
    "        af = np.where((af > -noise_level)&(af < noise_level), 0, af)\n",
    "        af = np.resize(af, (n_chunks,len_chunks))\n",
    "        \n",
    "        ar = ap.extract_audio(f\"../videos/{dir}/{row.original}\")\n",
    "        ar = np.where((ar > -noise_level)&(ar < noise_level), 0, ar)\n",
    "        ar = np.resize(ar, (n_chunks,len_chunks))\n",
    "\n",
    "        \n",
    "        for i in range(n_chunks):\n",
    "            if np.max(af[i]-ar[i]) > threshold:\n",
    "                save_melspectrogram(af[i], \n",
    "                                    f'FAKE_{row.video}_{i}',\n",
    "                                    le.to_categorical(['FAKE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FAKE from dfdc_train_part_49...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9a331e0c634095abe4671503603cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2619), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting REAL from dfdc_train_part_49...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1dd03c15234f6d9802ab9ecec62213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=515), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for d in dirs:\n",
    "    metadata = pd.read_json('../videos/' + d + '/metadata.json').T\n",
    "    metadata['video'] = metadata.index\n",
    "    \n",
    "    print(f'Extracting FAKE from {d}...')\n",
    "    extract_fake_audios(d, metadata, ap, le, threshold, n_chunks, len_chunks, inc_chunk)\n",
    "    \n",
    "    print(f'Extracting REAL from {d}...')\n",
    "    extract_real_audios(d, metadata, ap, le, n_chunks, len_chunks, inc_chunk)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import npz_in_folder\n",
    "files = npz_in_folder('../data/audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(files[42])\n",
    "log_S=data['data']\n",
    "label=data['label']\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_S.shape, label.shape, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_melspectrogram(log_S)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
